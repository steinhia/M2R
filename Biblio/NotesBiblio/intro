amorce 
Au quotidien, nous parlons rarement assis devant un micro sans bouger le reste de notre corps. Cette situation est pourtant celle que la recherche a longtemps privilégiée pour étudier les mécanismes de production de la parole. Or, dans la vie de tous les jours, nous parlons en bougeant tout notre corps et plus particulièrement nos mains. Ces gestes manuels font l’objet d’une littérature scientifique très développée, notamment dans la suite des travaux de David McNeil autour de l’équipe de recherche de Susan Goldin-Meadow à Chicago. Les études réalisées essentiellement chez l’enfant suggèrent l’importance du geste manuel dans la compréhension et l’apprentissage de la parole mais aussi dans le raisonnement verbal et l’apprentissage de connaissances (Cook et al., 2008; Goldin-Meadow & Wagner, 2005). 

L’intérêt pour la production de la parole en contexte de double tâche et/ou d’effort physique se développe dans la littérature, notamment relativement à des questions d’acquisition d’une langue seconde mais aussi de résolution de tâche, de créativité etc. (Oppezzo & Schwartz, 2014). Il semble en particulier que l’activité physique pourrait avoir un effet bénéfique sur l’apprentissage (Schmidt-Kassow et al., 2010).


1/ embodied cognition
 The dynamical system involved in speech is anatomically and functionally distinct from the one of arms and legs. But when producing, addressing or rehabilitating spoken language, the whole motor body actually plays a role or could be trained to play it. 
 Previous work suggests an embodiment of spoken language in limb movements at both conceptual and motor levels. Empirical observations suggest complex, adaptable and scalable links between the two systems. These dynamical aspects of speechElimb connection were yet poorly integrated in theories and models of speechEmotion interactions.  The breathing system, which is a shared physiological resource between limbs and speech, has however not been systematically investigated as a potential connector between the two systems. addresses the connection between spoken language and both nonEcommunicative (cyclical motions with the arms vs. the legs) and communicative motions (coEspeech hand/arm gestures).
anatomy = topic in embodied cognition because subject directly linked to body
The movements we make do not only act on the outer world but they also shape our cognitive abilities. A broad range of neurological and behavioral evidences suggest that the motor system is involved in perception, decision making, lexical representation, memory and emotional processes (Barsalou, 2008; Casasanto & Dijkstra, 2010; Glenberg & Kaschak, 2002; Tyler et al., 2003; Wexler,Kosslyn, & Berthoz, 1998).
cf. Barsalou, 2008; Borghi & Pecher, 2011; Clark, 1999; Varela, Thompson, & Rosch, 1993; Wilson, 2002)
According to the embodied cognition framework, mental functions are grounded in
sensory-motor processes linked to specific situations (“grounded cognition”, see Barsalou, 2008). Therefore, cognitive representations are not amodal but rather “grounded” in the sensory-motor processes involved in their construction. In knowledge acquisition, as in all experiences, “the brain captures states across the modalities and integrates them with a multimodal representation stored in memory” (Barsalou, 2008, p.618).
In this framework, cognitive processes rely on simulation
mechanisms that could be defined as “the reenactment of perceptual, motor, and introspective states acquired during experience with the world, body, and mind” (Barsalou, 2008, p.619). As specific cases of sensory-motor experiences, and due to their powerful representational and deictic functions, manual gestures are the core interest of a variety of studies focused for instance on the role of gestures in language, conceptual learning, problem solving or spatial representations. The positive effect of gestures in these cognitive activities has been shown when seeing the gestures made by another person (a teacher, a discussion partner etc.) and when making the gestures.
Our study investigated the effect of a direct implication of the motor system when learning structural and functional anatomy. The results suggest that “doing gestures” is more effective than just “seeing gestures” while learning the names of anatomical structures. Such effect was previously observed at short-term in a mental rotation task (Goldin-Meadow et al., 2012) and is consistent with the idea that “motor information accrued by the body can affect learning and development by grounding mental representations in motor areas of the cortex and structuring associated perception” (Kontra, Goldin-
Meadow, & Beilock, 2012; p732).
Dans le cadre de la cognition incarnée et située, nous adoptons l’idée que la majorité de nos activités cognitives sont une ‘réactivation d’états perceptifs, moteurs et introspectifs acquis durant une expérience avec le monde, le corps et la pensée’(‘Simulation is the reenactment of perceptual, motor, and introspective states acquired during experience with the world, body, and mind’, Barsalou, 2008, p. 618). Si les mécanismes sensoriels et moteurs sont intégrés dans les processus cognitifs, la compréhension des processus cognitifs requiert de considérer ces mécanismes. En particulier, l’activité corporelle qui advient avec la parole et que nous qualifierons de « substrat corporel » (ou « body ground » par écho au terme de « grounded cognition » employé par Barsalou), devient un acteur incontournable, et dont l’étude requiert une bidirectionnalité entre les sciences du langage et les sciences du mouvement, au cœur de notre projet. Ce substrat corporel peut s’envisager sous l’angle des caractéristiques individuelles (propriétés corporelles et physiologiques héritées et acquises) et sous l’angle de la contrainte situationnelle (mains libres, mains prises, activité manuelle ou de locomotion, effort physique plus ou moins soutenu), avec une interaction probablement très forte entre les deux. Il intégrerait aussi un troisième acteur encore trop souvent négligé dans l’étude de la parole : la respiration, ressource partagée entre la production de la parole et les mouvements des membres. La respiration pourrait d’abord jouer un rôle de coordinateur entre la parole et le mouvement des membres et de cette coordination pourrait dépendre les capacités d’expression et d’apprentissage verbaux. Elle jouerait aussi un rôle dans la mémorisation des informations puisque l’oxygénation des organes, incluant le cerveau dépend d’elle.
A growing amount of behavioral and neurophysiological research shows the implication of limb movements in cognitive activities. For example, manual gestures facilitate learning abstract knowledge such as mathematical concepts (Cook et al., 2008; Perry et al., 1988; GoldinEMeadow and Wagner, 2005); 
language understanding involves motor areas in the brain (e.g., Pulvermüller et al., 2005) and motor systems interact with language comprehension (Glenberg and Kaschak, 2002). In the ‘grounded’ cognition framework, these results are integrated as evidence that most of our cognitive activities are a “reenactment of perceptual, motor, and introspective states acquired during experience with the world, body, and mind” also called “simulation” (Barsalou, 2008, p. 618; see also Varela et al., 1993; Clark, 
1998). 
These approaches change the perspectives on cognitive abilities, and language in particular (Lakoff, 2012; Glenberg, 2015): to improve our understanding of spoken language, research should embrace the body’s states and situations in which they occur. Learning and memory are core phenomena in this process, leading to a better understanding of the path from experience to cognition. 
Some earlier studies already integrated the physical properties of the speech motor system as a determinant of spoken languages and, in particular, phonological systems (Ohala, 1978; Liljencrants & Lindblom, 1972; Lindblom, 1984). In general, physical properties are still poorly integrated in phonology, pragmatics, syntax or motor control models of speech production (Bohland et al., 2010). 
Body states accompanying spoken language are manifold and occur at different levels. Speech is often produced while moving the arms or the legs for nonEcommunicative (e.g., talking with a friend while walking on the way to work), or communicative purposes (e.g., pointing to a place or an object). 
Previous work showed that these coEoccurrences lead speech and limbs to influence each other. Moving and talking at the same time could be seen as a dual task, especially when limb motions do not serve a communication purpose or when they convey a concurrent message. But they could also be seen as a context integrated in the motor and lexical learning of spoken language and later ‘reenacted’. 
Salammbo is built on interdisciplinary evidence of multiElevel influences of body actions on spoken 
language and on “grounded” approaches of cognition. It will contribute to a better understanding of these influences, their adaptability and learning through the study of adult populations with different profiles, and through the exploration of nonEcommunicative and communicative motions. 
Evidence for the complex, adaptable and scalable links between spoken language and limb movements comes from interdisciplinary research, with different aims and methods. This provides an interdisciplinary scientific background to the project, of which the first innovation is to connect these areas Manual gestures are omnipresent in spoken communication (Feyereisen & deLannoy, 1991)
For some authors, speech and manual gestures are integrated in communication (McNeill, 1992). Manual gestures have actually been hypothesized to be precursors of spoken communication (Corballis, 2003; Glenberg and Gallese, 2012).


2/we spontaneously do gesture when communicating
Manual gestures are part of communication. We all move our hands and arms while we speak and researchers have argued that these gestures “are an integral component of the communicative act of the speaker” (Kendon, 2004; p. 359). According to the growth point theory, gestures and speech stem from a common thought process (McNeill, 1992; McNeill & Duncan, 2000; McNeill et al., 2008). They would even be controlled by the same motor system (Gentilucci & Dalla Volta, 2008). The brain integrates both signals when perceiving a communicative act (e.g., Özyürek et al., 2007) even though the networks involving the processing of the two modalities do not overlap completely (Bernardis, Salillas, & Caramelli, 2008).
manual gestures are mastered more easily by infants than speech (e.g., Goodwyn & Acredolo, 1993).
Among the various body actions shown to influence our cognitive
abilities, research paid particular attention to manual gestures, due to their multi-faceted representative function and their special relationship to language (Goldin-Meadow & Alibali, 2013;McNeill, 1992). Manual gestures are commonly and spontaneously used by speakers, learners and teachers. They were shown to support language learning on receptive and expressive sides as well as conceptual learning and problem solving (Kontra, Goldin-Meadow, & Beilock, 2012; Novack & Goldin-Meadow, 2015).

In a daily basis, people are spontaneously gesturing in order to communicate. These gestures can mark the rhythm of the discourse, strengthen the message or provide additional information to the listener.
gestures could represent “a second channel that makes successful comprehension more likely” (Goldin-Meadow & Alibali, 2013, p.261).
The effect of gestures on language comprehension however depends on the information contained in the gestures (Goldin-Meadow & Alibali, 2013)
During class, teachers spontaneously gesture when they have to explain mathematical concepts to children (Goldin-Meadow, Kim, & Singer, 1999)

3/ link gesture/language
Early gestures do not only predict the lexical items, they also predict the vocabulary range (Iverson & Goldin-Meadow, 2005)
An opened question is then: Is the beneficial effect of gestures related to the type of link between the gestures and knowledge to learn?
Gestures seem to be useful in different domains (Susan Goldin-Meadow & Alibali, 2013; McCafferty, 2004; Novack & Goldin-Meadow, 2015; Trofatter et al., 2014) but the relevance of the link between learning content and gestures type remains an opened question.
The first gestural communicative acts have also been shown to predict the onset of the first words (e.g., Iverson & Goldin-Meadow, 2005; Goldin-Meadow, 2007).
Gesture use is predictive of later vocabulary size (Rowe, Özçalışkan, & Goldin-Meadow, 2008).
Taken together, this research suggests that children naturally produce manual gestures to communicate and that these gestures play a role in language acquisition, not only before speech onset but also later (Özçalışkan & Goldin-Meadow, 2005).
All this put together suggests that manual gestures play a role in acquiring speech and language (Capirci & Volterra, 2008) even though it still remains unclear what this exact role is.
To learn a new word, one has to map both a meaning and a lexical form to a concept, which can be respectively labeled as semantic and lexical learning. “Word learning is a complex task that requires (…) to create new semantic and lexical representations, then link these new representations and integrate them with existing phonological, lexical, and semantic representations” (Kapalková, Polišenská, & Süssová, 2016, p. 59).

4/ gestures help to learn
Manual gestures can facilitate problem solving but also language or conceptual learning. Both seeing and making the gestures seems to be beneficial to cognitive tasks and learning. 
Interestingly, Singer & Goldin-Meadow (2005) found that seeing gestures during a lesson of mathematics improves performance 24 hours after the lesson and tends to facilitate transfer to other problems solving.Teachers’ gestures can help children understand and integrate instruction, which can explain the positive effect on long-term performances. Here again, gestures should convey supplemental information to verbal information to be helpful: when children learn mathematics, they only improved when the teachers’ gestures bring a different way to approach the problem than the teacher’s spoken message.
Chen (1996) have shown that gesturing while speaking could facilitate access to the mental lexicon in spontaneous speech produced by undergraduate students (Rauscher, Krauss, & Chen, 1996)
adults can learn a second language easier if they gesture during learning (Gullberg, 2006; McCafferty, 2004)
the teacher’s gestures is already helpful for learning (Cook et al., 2013) 
manual gestures vs pictures -> mieux gesture group Kapalková, Polišenská and Süssová (2016) 
Booth, McGregor and Rohlfing (2008) 1. using pointing to the object to learn its label; 2. additionally touching it; 3. additionally moving it across the table (in TD children) -> avantage pointing comparé a word alone, pas les 2 autres
Five studies (Capone & McGregor, 2005; Booth, McGregor, & Rohlfing, 2008; McGregor et al., 2009; de Nooijer et al., 2014; Lüke & Ritterfeld, 2014) involving a total of 212 children put forward a significant positive advantage of adding manual gestures during training to learn new words either expressively, receptively or both
 the gestures used during training were produced by adults.
Evidence also suggests that manual gestures facilitate lexical access in adults (e.g., Rauscher, Krauss, & Chen, 1996; Krauss & Hadar, 1999).
Gestures have indeed been shown to promote the learning of words in a foreign language in children (Tellier, 2008 but see Rowe, Silverman, & Mullan, 2013) and adults (Macedonia & von Kriegstein, 2012; Kelly et al., 2014; Macedonia & Repetto, 2016) Rowe, Silverman and Mullan (2013) put forward the fact that this effect is dependent on the individual.
the effect on manual gestures during TRAINING idem Goldin Meadow
Q1 : wd+gest>gest only
Q4 : pointing ou iconic > other additional cues

5/ better results if gesture more
For instance, in Church & Goldin-Meadow (1986), children had to explain their understanding of the concept of conservation while judging the same amount of water poured into two glasses with different shapes. When they explained their reasoning to solve the problem, some of them spontaneously produced gestures matching their reasoning while others produced gestures mismatching their reasoning. The latters were more likely to understand their mistakes, and better improve their performance than the formers.
Hanoi : (Trofatter, Kontra, Beilock, & Goldin-Meadow, 2014) The students who made gestures during their explanation showed a greater improvement when they solved the Tower of Hanoi again than those who did not make gestures.
Students who gestured during learning had better performance than those who did not, both for the terminology (“knowledge of specific definitions and labels”) and comprehension (understanding of the structures and functions of the heart) tests (Macken & Ginns, 2014; p 598).
profils de gesturers, pas tous à l'aise pour faire des gestes.
Some interesting observations come from studies in which imitation was not forced and which analyzed the correlation between imitation and word learning performances. In Bird et al. (2000), the participants were not required to, but could, imitate the gestures during training. Correlational analysis showed no correlation between imitation vs. none and word learning performance for children with T21, but did find moderate to high correlation for TD children
In a nutshell, producing the manual gesture during training does not appear to be absolutely necessary since several studies find a gestural advantage even if the children only observed the gesture during training. A few, but not all, studies however showed a positive correlation between production of the manual gesture during training and better word learning performances.

6/ différents types de gestes : iconicité importante ?
Vogt and Kauschke (2017a) ran an interesting follow-up experiment to their main study comparing iconic and attention-directing gestures. It compared the use of iconic gestures versus arbitrary ones. Even though sample size was small (18 TD children) and impeded reaching statistical significance (according to the authors themselves), the results suggest that both expressive and receptive performances were higher for the iconic than the arbitrary gesture condition.
Mollink, Hermans and Knoors (2008) found a positive effect of adding signs to words for receptive word learning in hearing impaired children. They analyzed this effect as a function of sign iconicity. Even though the effect was the same for signs with strong iconicity than for those with weak iconicity one week after training, the results after five weeks show that learning was better for strongly iconic signs. The interesting thing is that at five weeks, the performance decreased compared to one week only for weakly iconic signs but remained the same for strongly iconic signs suggesting that iconicity helped longer memory retention.
Another surprising observation, taking into account the results of Marentette and Nicoladis (2011), is that Lüke and Ritterfeld (2014) found no advantage of iconic gestures over arbitrary ones. This could be due to a ceiling effect for iconic gestures (as suggested by the authors themselves).
Capone Singleton (2012) compared iconic gestures underlying shape to pointing. She found that shape gestures were more efficient in promoting expressive and receptive word learning than pointing.
Overall, the studies reviewed here suggest that different types of manual gestures can have differential effects. Pointing gestures appear to be helpful for word learning compared to no gesture even though there is some evidence that gestures having an iconic resemblance with the referent would be more effective. 
 Marentette and Nicoladis (2011) found that children aged 40 to 60 months could learn iconic gesture labels for objects but not arbitrary gesture labels mais existe contraire


7/active learning expressive vs receptive learning ? 
Q8 : obserger gestes suffit ou doit produire ?
being active during learning is an important element in the research about learning and memory: Should learners gesture themselves or is seeing the teacher’s gestures enough?
Evidence suggesting that action itself rather than attention supports active learning is provided by Meijer & Van der Lubbe (2011): an active exploration of 3D objects leads to a better recognition of these objects than a passive exploration, even if participants had to carry out a secondary task during learning.
Previous work also suggests that being active during learning of anatomy improve the feeling of involvement, especially when innovative methods are used (cf. Sugan et al., 2010)
Some studies have indeed shown that imitating the gesture during training improves the beneficial effect of manual gestures for learning words in a foreign language (e.g., Macedonia, Bergmann, & Roithmayr, 2014). 
Q8: producing vs observing gestures : selon les études, pas obligatoire pour effet des     gestes ou effet positif supplémentaire
    Production of the gesture during testing could also yield better recall performance
A total of five studies (Capone & McGregor, 2005; Booth, McGregor, & Rohlfing, 2008; McGregor et al., 2009; Lüke & Ritterfeld, 2014; Mumford & Kita, 2014) found a positive effect of adding a gesture during training to learn new words through observation of gesture in TD children
Some interesting observations come from studies in which imitation was not forced and which analyzed the correlation between imitation and word learning performances. In Bird et al. (2000), the participants were not required to, but could, imitate the gestures during training.
Correlational analysis of  correlation between imitation vs. none and word learning performance, showed  moderate to high correlation for TD children.
de Nooijer and colleagues (2014) tested receptive verb learning and included both a condition in which participants only observed the gesture and one in which they were also asked to imitate the gesture. They did not find any advantage of imitating the gesture rather than just seeing it.
It could also be the case that producing the gesture upon recall could facilitate the latter. Only one study directly controlled for gesture production during testing. O’Neill, Topolovec and Stern-Cavalcante (2002) found a positive correlation between descriptive gesture production during testing and receptive performance in TD children only for two out of the five adjectives learned in experiment 1 but for all adjectives in experiment 2.

expe PDAmélie
obj : rôle des gestes dans l'acquisition de nouvelles connaissances making>seeing
Making gestures to learn anatomy is also a specific case of embodied active
learning, in which explicit knowledge on the body is developed throughout the implication of the body
The effect of making gestures was assessed by comparing two groups of participants (seeing vs. making gestures) both in terms of performance and subjective evaluation.
Gesture behaviors were also monitored during the learning and test phases and the quantity of gestures made was related to the scores in the different evaluations.
Ability to memorize complex unknown words, assessed using a list of 8 pseudo-words with
two or three syllables that we generated from the Lexique 2 database (New, Pallier, Ferrand, & Matos, 2001). The pseudo-words were selected to have different orthographic organization.
The purpose of this study was to provide further evidences that making gestures can improve the acquisition of new knowledge. Anatomy learning was chosen as a specific case of embodied learning and as a challenging topic to learn. In particular, we focused on the specific contribution of making gestures in relation to the learning content as compared with just seeing gestures
(1) the positive effect of making gestures could be present at short-term but hard to observe due to between-subjects design and to the multi-dimensional competences involved in complex learning such as anatomy; (2) longitudinal assessments should be planned systematically in learning studies, especially when comparing learning conditions, as some conditions may need sleep and/or time to be integrated




8/ effect on time
Furthermore, the participants in the Gesture group were not only better than
those of the Control group: they also significantly improved their scores as compared with short-term assessment.
Similar beneficial effects of gestures on long-term learning was previously observed in
Cook et al., (2008) and Cook, Yip, & Goldin-Meadow (2010) and could be related to effects of sleep on memory. Literature broadly reported positive effect of sleep on memory consolidation (Diekelmann & Born, 2010; Rasch & Born, 2013).
long-term effect of gestures on learning (Cook et al., 2008).
gestures “make learning last” (Cook et al., 2008).
Lüke and Ritterfeld (2014) also found a gestural advantage only after a one-week delay and not immediately for expressive learning.
Finally van Berkel-van Hoof and colleagues (2016) found that the gestural advantage grew over time.
Mollink, Hermans and Knoors (2008) compared word learning performances after one and five weeks. They found a gestural advantage but no differential effect between strong and weak iconicity signs after one week. After five weeks, performance decreased but only for weak iconicity gestures and not for strong iconicity ones. This suggests that iconicity favors longer memorization.
The authors also analyzed the correlation between short-term and long-term performances and found, only for the gesture group, that “children who demonstrate modest gains on the immediate post-test build on those gains for a more impressive performance at delayed post-test” (p. 819) and this only for unlearned combinations:
Q7 : does testing time matters ? STM/LTM
McGregor and colleagues (2009) however find a larger effect of gesture (over speech only) on the receptive acquisition of the preposition ‘under’ only after two to three days and not at immediate testing and only for generalization (not for trained pairs of objects)
McGregor and colleagues (2009) compared the learning of the preposition ‘under’ in three groups of TD children: one with the word only, one with an additional manual gesture, and one with a photograph. The results show that performance improved from pre-test to immediate testing after training to a similar extent in all groups. A further analysis, however, showed a manual gesture advantage when comparing performance at pre-test and delayed post-test. This suggests that manual gestures promote learning more than photographs, not immediately after training, but after a two- to three-day delay. Manual gestures would thus be more efficient for maintaining word learning over time.
It appears that the gesture plays a different role than other additional cues such as pictures.
Q5 : expre vs recept : rec > ac gestures si pas trop de mots
     avantage manuel à expressif slmt après plusieurs sessions
Q6 : types of gestures :  pointing < iconic gestures (controversé), 2 ont effet
-> après tps, moins iconique = - utile
Q7 : testing time : immediate, slmt pour receptive learning, + long pr expressif


9/ Link with sport 
Another body of research focused on the effect of physical effort on speech production with different aims. Physical effort affects the phonetic and phonological properties of speech A clear effect has been observed on prosody. Skutella et al. (2014) found that in faceEtoEface inEdoor biking involving an instructor and a trainee, pitch and verbal rhythm were congruent with posture and movement tempo of the trainer. 
Trouvain & Truong (2015) introduce the ‘Talk and Run’ database involving 23 participants reading different texts before, during, and after running on a treadmill. They recorded speech acoustics and different parameters such as step frequency and heart rate and showed higher speech rate, f0 and longer averaged breath durations in text reading after running than before. Physical activity also impacts spectral properties of phones. Godin & Hansen (2011) found a larger effect of physical activity on nasals than plosives and fricatives while using a stepper. This effect may be related to breathing strategies (e.g., leaving the velar port open to inhale via the nostrils). 
Dual task paradigms involving limb movements and speech production provide additional information to understand the interaction of the two systems. For example, studies on the effect of speaking on the telephone on walking towards a particular local target showed divided attention and strong deviations from the target (Lambert & Muratori, 2012). This can become a real danger, particularly when pedestrians cross a street while talking on the phone, without paying attention to the traffic. 
In general, even if dual tasks studies are manifold they often show a lower cognitive processing speed and slower motion in comparison to comparable single tasks (for a comprehensive review, see AlEYahya et al., 2011). 
9b/ motion 
Gestures'and'motion'for'lexical'access,'learning'and'memory'
In the Lexical Access Theory, Krauss (1998) postulated that motoric gestures help in the retrieval of words from memory, something which is supported by evidence from several studies. 
For instance, interpreters use beat gestures during simultaneous interpreting (Adam & Castro, 2013) even when they are not visible to the addressee. These gestures often occur during hesitations or utterances with pauses, showing uncertainty of the interpreter, and facilitate word retrieval. Ravizza (2003) found that, when learning rare words, hand tapping during the recall phase favours word retrieval, as compared with being immobile during this phase. 
Body activity can also improve verbal creativity or learning new vocabulary. Oppezzo & Schwartz (2014) investigated the effect of walking vs. sitting in two creativity tests. Participants tremendously improved their performance while walking, or when performing the tests shortly thereafter. The authors did not interpret their results with respect to lexical access explicitly, but the results are congruent with the literature on this topic. 
SchmidtEKassow et al. (2010) compared learning and memorizing the vocabulary of a new language while sitting or biking or walking (SchmidtEKassow et al. 2014). After several sessions of learning, the findings reveal an improved memory of the newly learned vocabulary as well as changes in brain plasticity. Typical and atypical motors abilities. 
Speech and limb motions involve two different systems, with different muscles, tissues, bones etc. Obviously, these systems can be trained independently. 
However, it is possible that specific training such as sports practice could transfer from speech to limb and the reverse. How and when this transfer occurs is still not understood. One possibility is that it may occur thanks to breathing. 
Manual gestures, or methods involving the body (see above) are increasingly used in rehabilitating children with DS to improve their communicative skills and acquire speech (cf. Kumin, 2012; Wright et al., 2013). Spoken language abilities in children with developmental delays, including children with DS might be related to 
their motor skills (Houwen et al., 2016; Iverson, 2010). 



10/explanation of these effects : attention getter ?
- gestes during training = attention getter ?
Joint attention (Tomasello, Carpenter, & Liszkowski, 2007), which is important for learning, would be enhanced by the gesture
Put together, all this evidence suggests that either gestures have an additional role than just attracting the learner’s attention, even more so for iconic representational gestures, or that gestures attract attention more than other cues as hypothesized by McGregor and colleagues (2009): “gestures are interesting, and thus draw more attention to moments of training” (p. 822).
“Whereas both pointing and iconic gestures can draw attention to an abject, the iconic gesture may also orient children to attend to or strengthen their inferences about specific features and their connection to the word label” Capone Singleton (2012)
Kapalková, Polišenská and Süssová (2016) found that providing a manual iconic gesture during training yielded better expressive learning performances compared to providing a picture.
This suggests that there is something more to manual gestures than just drawing attention to the word learning context.
Booth, McGregor and Rohlfing (2008) compared the use of pointing towards the labeled object and the use of gaze towards the latter. They found that learning performances are better in the pointing than in the gaze condition. They also controlled for child attention by analyzing looking time of the participants when the experimenter labeled the object during learning. They found that the participants’ looking time towards the target object did not differ between conditions. This suggests that the level of attention was the same across conditions and that, even so, the use of pointing enhanced receptive word learning.


10/explanation of these effects : sleep
Therefore, one or two nights of sleep could enhance memory traces by a (re)-simulation of experience (reactivation in the hippocampus) and a reorganization of the memory traces (by the dialogue between hippocampus and neocortex).
Sleep has a beneficial effect both on declarative and procedural memory (Plihal & Born, 1997; Rasch & Born, 2013).
Sleep is for example well known to have a positive impact on procedural memory and visuo-spatial tasks (Fischer, Drosopoulos, Tsen, & Born, 2006; Peigneux et al., 2004; Björn Rasch, Büchel, Gais, & Born, 2007),


10/explanation of these effects : memory
All these studies suggest that when manual gestures are present during encoding of the memory, it is better encoded. 
Manual gestures could function as additional traces to help the learner memorize the new words more efficiently. Several of the studies reviewed in this chapter provide insight on this hypothesis. McGregor and colleagues (2009) put forward a gestural advantage only after two- to three-days and not immediately.
The difference between the two groups also suggests that “seeing gestures” vs. “doing gestures” create different memory traces. -> postdoc Amélie

10/explanation of these effects : grounded cognition
Short-term subjective evaluations suggest that the Gesture group felt more engaged in the lecture than the Control group
The stronger motor activation when making gestures as compared to seeing gestures during learning may influence the reactivation of experience and the reorganization of memory during sleep, favoring the integration of the motor component.
In terms of cognitive processes, we can assume that doing gestures during learning is a way to enhance the memory traces associated with learning. According to embodied cognition theories (Barsalou, 2008; Wilson, 2002), cognition emerges in the interaction between the body, the mind and the environment. Memory is defined by every sensory and motor component activated while experiencing the events from daily life (Logan, 1988; Versace et al., 2014). Several memory models are developed according to this idea and usually describe that the number of components of a memory trace can influence its strength (Versace et al., 2014). We can consider that having a supplemental motor component during learning (for the Gesture group) can strengthen the memory trace associated to this learning, if there is enough time (and/or sleeping processing) between learning and retrieval. The embodied cognition theories also suggest that memory is in fact a simulation of previous events (Barsalou, 2009; Barsalou, Pecher, Zeelenberg, Simmons, & Hamann, 2005). Adding a motor component to learning may facilitate the simulation process.
Indeed, a stronger activation of the motor system in the former case may create additional components to the memory traces and/or contribute to shape abilities to mentally simulate the function (Barsalou, 2008).


10/explanation of these effects : cognitive load minimization
Gestures could facilitate word learning by enhancing memorization and/or alleviating cognitive load.
Manual gestures may also minimize the cognitive load involved in word learning as suggested by Goldin-Meadow and colleagues (2001). -> mémoriser une séquence de lettres, puis résolvent un pb de math, puis recall -> gestes pdt math pb > car save space for memorizing sequence of letter     
McGregor and colleagues (2009) suggest that gesture “externalized a meaningful aspect of the referent in the visual world. By making that meaning more obvious, gesture may free cognitive-linguistic resources for processing the word itself and, perhaps the other lexical and syntactic elements involved” (p. 823). Gestures could help reinforce the link between the lexical form and the concept it refers to by putting forward a distinctive property of the meaning the word refers to, depicting it and attracting the learner’s attention to it. Illustrating this link could free part of the cognitive load involved in finding this property and processing this link. This could free more cognitive load to actually learn the lexical form associated with it.         


Salommbo : Spoken lAnguage in motions Learning and Adaptations of speech coMMunication in the context of BOdy motions 
Recently, we recorded participants while speaking only, biking only or speaking and biking at the same time with various biking efforts. Acoustical signals, breathing kinematics (Inductance Plethysmography) and limb movements (Optitrack) were recorded synchronously. Preliminary analyses showed that: as physical effort reduces the duration of the breathing cycles, speakers compensated for the shorter temporal window by increasing their speech rate. They also increased loudness and f0 (Fuchs et al., 2015).
direct investigation of the “body ground” on speech production


SALAMMBO
Investigating the close link between speech gestures, breathing and spontaneous speech 
in unconstrained communication (WP1) 
 Investigating the impact of different types of motion (arms, legs, hands), communicative or not, on learning and memorizing the words of a novel language (WP2) 
 Using fundamental knowledge to support applied areas such as foreign language 
learning and speech and language therapy (WP1 and 2). 
) compares the motion of different limbs (arm vs. leg) and of different types (nonEcommunicative and communicative movements) and their impact on breathing and spoken languag 
extends the approach to learning and memorizing new words by linking speech motor learning to lexical learning. 
Salammbo will have an impact on our theoretical understanding of how spoken language is grounded in sensorimotor processes and situational contexts. It will contribute to a further methodological development for studying multimodality and will enhance the ecological validity of the experiments from more to less controlled experimental paradigms. 
 Finally, among the first papers about phonetic properties of speech during or after motion are the ones for speech recognition. Schuller et al. (2013) state: “if physiology parameters can be reliably estimated from a normal speech signal, the door to many, novel and innovative applications is opened.” 
(p. 1506).
fin intro : La respiration et les mouvements des membres dans la narration verbale

RESUME
within the framework of grounded cognition, evidence that sensorimotor processes are involved in cognition, and particularly in spoken language, but limited number of direct investigation of limb movements and speech production. This investigation needs to be developed in close connection  to speech analyses to bring our knowledge of the ‘body ground’ of spoken language a step further. 
• limb movements and speech share cognitive and physiological processes, with manifold links and adaptations at the executive, learning, memory, and central processing levels. These links and mutual adaptations are, however, still not well understood. Our analysis is that transversal integrated approaches are missing in previous work. For example, the prosodic, phonetic, phonological, lexical, syntactic levels of speech production were often considered independently. 
Communicative and nonEcommunicative limb movements, arm vs. leg movements were discussed separately but not very often compared.  Developing an integrated approach of these different levels is now required to embrace the complexity of the link 
between spoken language and limb movements.  



Le but général du projet est d’interroger comment les mouvements des membres supérieurs et inférieurs et la respiration interagissent avec : (1) la production de la parole et (2) l’apprentissage de nouvelles informations et en particulier de nouveaux mots
En étudiant les interactions parole-respiration-mouvements des membres au niveau de la production de la parole et de la mémorisation de nouvelles informations, nous contribuerons à une meilleure compréhension du rôle des fonctions motrices et physiologiques dans la communication verbale. Au delà de son importance fondamentale, cette compréhension est requise pour développer des protocoles d’éducation et de rééducation de la parole s’appuyant sur le corps, tels que ceux qui existent déjà mais qui sont encore sous-utilisés du fait d’un manque de validation empirique et de support objectif.
(1) la production de la parole, en étudiant l’effet de différents types de mouvements sur la production de la parole à différents niveaux linguistiques ; et (2) l’apprentissage d’informations verbales, en étudiant l’évolution de la mémorisation d’informations sur plusieurs sessions dans des tâches de narration incluant des nouveaux mots. Une partie du projet est aussi dédiée à l’analyse des gestes spontanés accompagnant la parole afin de les caractériser par des paramètres cinématiques et pouvoir étudier leur relation avec la parole et la respiration.

Hypothèses :
    (1) Les caractéristiques corporelles et l’activité physique des locuteurs influenceraient significativement la communication verbale, notamment via une spécificité du contrôle respiratoire. 
    (2) Les mouvements du corps font partie du contexte dans lequel nous nous exprimons : leurs variations auraient un impact sur la forme et le contenu de notre parole modulés par la négociation respiratoire entre contrôle de la parole et le contrôle des mouvements des membres. 
    (3) Le fait de bouger les membres pourrait améliorer la mémoire à long terme de la narration d’un événement et l’apprentissage d’un nouveau vocabulaire. En effet, les mouvements des membres semblent améliorer différents types d’apprentissage, ces effets devraient être plus clairs avec la pratique et avoir des corrélats dans les profils de coordination parole-respiration-mouvements des membres. Plus particulièrement, nous nous attendons à un avantage des conditions « mains libres » et « pédalage avec les jambes » sur les conditions « mains immobiles » ou « mains pédalant », du fait du rôle spécifique de la gestualité manuelle dans la production de la parole, une contrainte sur les mains pourrait interférer avec la narration.
Les effets attendus de l’interaction entre parole, respiration et mouvements devraient :

    (4) Affecter différents niveaux linguistiques : syntaxiques, lexicaux, phonologiques, et phonétiques.
    (5) Être spécifiques au type de mouvement (les gestes communicatifs, les gestes cycliques avec les mains ou les jambes) et liés à la respiration.
En résumé, nous supposons un effet positif du mouvement sur la parole qui devrait être spécifique aux types de mouvements et s’observer surtout avec la pratique, sur la rétention à long terme. Nous nous attendons à une évolution des profils de coordination parole-respiration-mouvements des membres au fil des sessions corrélées à une consolidation de la mémoire et à des profils spécifiques de production de la parole à différents niveaux linguistiques. 
PWP2 will focus on learning to produce and memorize novel words (object names) with different phonology (new language) or pseudoEwords by: 
(1) investigating how different kind of limb movements (cyclical motion with the arm vs. the legs vs. iconic gestures related to the shape of the object) produced while learning new words affect the way these words are produced (motor learning) and memorized; 
(2) studying the coEevolution of speech and motion in the course of learning; 
(3) analyzing if and how, when both speech and limb motor systems are impaired (Down 
Syndrome), limb movements could still support speech learning and memorization of new 
words.
Both WPs will involve detailed analyses of different parameters of speech production, based mainly on acoustical recordings but also, for a subEpart of WP2, on articulatory motion. The project will also analyze different linguistic levels, including syntactic structure and vocabulary (in spontaneous speech, see WP1). 
Breathing and kinematics of the limbs will be analyzed jointly. The project will thus merge methods from different fields. A last working package, WP3 will aim at adapting these different methods, and provide new ones. 
The results of the project will have an impact for theories of speech production and language. They will also provide insights for education and rehabilitation of speech and language. These aims will be achieved thanks to a close collaboration between the French and German teams who have complementary skills, covering the spectra required for conducting this project. 

