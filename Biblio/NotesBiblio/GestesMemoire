###########################################################

Do manual gestures help the learning of new words? A review of experimental studies

#########################################################################
We all produce manual gestures when we speak and these gestures have been shown to play an important role in the act of communicating
semantical and lexical learning
Questions posées :
- avantage d'utiliser gestes pour app nvx mots ?
- manuel gestures vs additional clues ?
- différents types gestes ont différents effets ?

INTRO
Manual gestures are part of communication. We all move our hands and arms while we speak and researchers have argued that these gestures “are an integral component of the communicative act of the speaker” (Kendon, 2004; p. 359). According to the growth point theory, gestures and speech stem from a common thought process (McNeill, 1992; McNeill & Duncan, 2000; McNeill et al., 2008). They would even be controlled by the same motor system (Gentilucci & Dalla Volta, 2008). The brain integrates both signals when perceiving a communicative act (e.g., Özyürek et al., 2007) even though the networks involving the processing of the two modalities do not overlap completely (Bernardis, Salillas, & Caramelli, 2008).
manual gestures are mastered more easily by infants than speech (e.g., Goodwyn & Acredolo, 1993).
The first gestural communicative acts have also been shown to predict the onset of the first words (e.g., Iverson & Goldin-Meadow, 2005; Goldin-Meadow, 2007).
    Gesture use is predictive of later vocabulary size (Rowe, Özçalışkan, & Goldin-Meadow, 2008).
Taken together, this research suggests that children naturally produce manual gestures to communicate and that these gestures play a role in language acquisition, not only before speech onset but also later (Özçalışkan & Goldin-Meadow, 2005).
All this put together suggests that manual gestures play a role in acquiring speech and language (Capirci & Volterra, 2008) even though it still remains unclear what this exact role is.
To learn a new word, one has to map both a meaning and a lexical form to a concept, which can be respectively labeled as semantic and lexical learning. “Word learning is a complex task that requires (…) to create new semantic and lexical representations, then link these new representations and integrate them with existing phonological, lexical, and semantic representations” (Kapalková, Polišenská, & Süssová, 2016, p. 59).
Gestures have indeed been shown to promote the learning of words in a foreign language in children (Tellier, 2008 but see Rowe, Silverman, & Mullan, 2013) and adults (Macedonia & von Kriegstein, 2012; Kelly et al., 2014; Macedonia & Repetto, 2016) Rowe, Silverman and Mullan (2013) put forward the fact that this effect is dependent on the individual.
Evidence also suggests that manual gestures facilitate lexical access in adults (e.g., Rauscher, Krauss, & Chen, 1996; Krauss & Hadar, 1999).

Q1 : advantage of adding gestural cue for learning new words in TD children ?
Five studies (Capone & McGregor, 2005; Booth, McGregor, & Rohlfing, 2008; McGregor et al., 2009; de Nooijer et al., 2014; Lüke & Ritterfeld, 2014) involving a total of 212 children put forward a significant positive advantage of adding manual gestures during training to learn new words either expressively, receptively or both
 the gestures used during training were produced by adults.

Q2 ; with children with language deficits ?
The results of the reviewed studies therefore suggest that manual gestures could help children with speech and language difficulties learn new words,
All other studies found an advantage of using manual gestures for learning new words, whether it be expressively or receptively or both, in a total of 74 participants (children with T21: Kohl, Karlan, & Heal, 1979; Bird et al., 2000; Romski & Ruder, 1984 – children with SLI: Lüke & Ritterfeld, 2014 – children with hearing impairments: Mollink, Hermans, & Knoors, 2008; van Berkel-van Hoof et al., 2016 – children with cerebral palsy: Kohl, Karlan, & Heal, 1979)

Q4 : manual gestures more efficient than other additional cues ?
1. using pointing to the object to learn its label; 2. additionally touching it; 3. additionally moving it across the table (in TD children) -> avantage pointing comparé a word alone, pas les 2 autres
manual gestures vs pictures -> mieux gesture group Kapalková, Polišenská and Süssová (2016) 
!!!!!!!!!!!!!!!!!!!!!!!!
McGregor and colleagues (2009) compared the learning of the preposition ‘under’ in three groups of TD children: one with the word only, one with an additional manual gesture, and one with a photograph. The results show that performance improved from pre-test to immediate testing after training to a similar extent in all groups. A further analysis, however, showed a manual gesture advantage when comparing performance at pre-test and delayed post-test. This suggests that manual gestures promote learning more than photographs, not immediately after training, but after a two- to three-day delay. Manual gestures would thus be more efficient for maintaining word learning over time.
!!!!!!!!!!
It appears that the gesture plays a different role than other additional cues such as pictures.

Q5 : expressive vs receptive learning ? interaction with nb training sessions 
// identification/dénomination ?
Q6 : does gesture type matter ? does iconicity matter ?
 Marentette and Nicoladis (2011) found that children aged 40 to 60 months could learn iconic gesture labels for objects but not arbitrary gesture labels mais existe contraire
Another surprising observation, taking into account the results of Marentette and Nicoladis (2011), is that Lüke and Ritterfeld (2014) found no advantage of iconic gestures over arbitrary ones. This could be due to a ceiling effect for iconic gestures (as suggested by the authors themselves).
Vogt and Kauschke (2017a) ran an interesting follow-up experiment to their main study comparing iconic and attention-directing gestures. It compared the use of iconic gestures versus arbitrary ones. Even though sample size was small (18 TD children) and impeded reaching statistical significance (according to the authors themselves), the results suggest that both expressive and receptive performances were higher for the iconic than the arbitrary gesture condition.
Mollink, Hermans and Knoors (2008) found a positive effect of adding signs to words for receptive word learning in hearing impaired children. They analyzed this effect as a function of sign iconicity. Even though the effect was the same for signs with strong iconicity than for those with weak iconicity one week after training, the results after five weeks show that learning was better for strongly iconic signs. The interesting thing is that at five weeks, the performance decreased compared to one week only for weakly iconic signs but remained the same for strongly iconic signs suggesting that iconicity helped longer memory retention.
Capone Singleton (2012) compared iconic gestures underlying shape to pointing. She found that shape gestures were more efficient in promoting expressive and receptive word learning than pointing.
Overall, the studies reviewed here suggest that different types of manual gestures can have differential effects. Pointing gestures appear to be helpful for word learning compared to no gesture even though there is some evidence that gestures having an iconic resemblance with the referent would be more effective. 

Q7 : does testing time matters ? STM/LTM
McGregor and colleagues (2009) however find a larger effect of gesture (over speech only) on the receptive acquisition of the preposition ‘under’ only after two to three days and not at immediate testing and only for generalization (not for trained pairs of objects)
The authors also analyzed the correlation between short-term and long-term performances and found, only for the gesture group, that “children who demonstrate modest gains on the immediate post-test build on those gains for a more impressive performance at delayed post-test” (p. 819) and this only for unlearned combinations:


Q8 : obserger gestes suffit ou doit produire ?
Some studies have indeed shown that imitating the gesture during training improves the beneficial effect of manual gestures for learning words in a foreign language (e.g., Macedonia, Bergmann, & Roithmayr, 2014). 
Some interesting observations come from studies in which imitation was not forced and which analyzed the correlation between imitation and word learning performances. In Bird et al. (2000), the participants were not required to, but could, imitate the gestures during training. Correlational analysis showed no correlation between imitation vs. none and word learning performance for children with T21, but did find moderate to high correlation for TD children
In a nutshell, producing the manual gesture during training does not appear to be absolutely necessary since several studies find a gestural advantage even if the children only observed the gesture during training. A few, but not all, studies however showed a positive correlation between production of the manual gesture during training and better word learning performances.

RESUME 
the effect on manual gestures during TRAINING idem Goldin Meadow
Q1 : wd+gest>gest only
Q4 : pointing ou iconic > other additional cues
Q5 : expre vs recept : rec > ac gestures si pas trop de mots
     avantage manuel à expressif slmt après plusieurs sessions
Q6 : types of gestures :  pointing < iconic gestures (controversé), 2 ont effet
Q7 : testing time : immediate, slmt pour receptive learning, + long pr expressif
Q8: producing vs observing gestures : selon les études, pas obligatoire pour effet des     gestes ou effet positif supplémentaire
    Production of the gesture during testing could also yield better recall performance

HYPOTHESES
- gestes during training = attention getter ?
Joint attention (Tomasello, Carpenter, & Liszkowski, 2007), which is important for learning, would be enhanced by the gesture
Booth, McGregor and Rohlfing (2008) compared the use of pointing towards the labeled object and the use of gaze towards the latter. They found that learning performances are better in the pointing than in the gaze condition. They also controlled for child attention by analyzing looking time of the participants when the experimenter labeled the object during learning. They found that the participants’ looking time towards the target object did not differ between conditions. This suggests that the level of attention was the same across conditions and that, even so, the use of pointing enhanced receptive word learning.
This suggests that there is something more to manual gestures than just drawing attention to the word learning context.
Kapalková, Polišenská and Süssová (2016) found that providing a manual iconic gesture during training yielded better expressive learning performances compared to providing a picture.
“Whereas both pointing and iconic gestures can draw attention to an abject, the iconic gesture may also orient children to attend to or strengthen their inferences about specific features and their connection to the word label” Capone Singleton (2012)
Put together, all this evidence suggests that either gestures have an additional role than just attracting the learner’s attention, even more so for iconic representational gestures, or that gestures attract attention more than other cues as hypothesized by McGregor and colleagues (2009): “gestures are interesting, and thus draw more attention to moments of training” (p. 822).

MEMORY
Manual gestures could function as additional traces to help the learner memorize the new words more efficiently. Several of the studies reviewed in this chapter provide insight on this hypothesis. McGregor and colleagues (2009) put forward a gestural advantage only after two- to three-days and not immediately.
Lüke and Ritterfeld (2014) also found a gestural advantage only after a one-week delay and not immediately for expressive learning.
Finally van Berkel-van Hoof and colleagues (2016) found that the gestural advantage grew over time.
Mollink, Hermans and Knoors (2008) compared word learning performances after one and five weeks. They found a gestural advantage but no differential effect between strong and weak iconicity signs after one week. After five weeks, performance decreased but only for weak iconicity gestures and not for strong iconicity ones. This suggests that iconicity favors longer memorization.
All these studies suggest that when manual gestures are present during encoding of the memory, it is better encoded. 



COGNITIVE LOAD MINIMIZATION
Manual gestures may also minimize the cognitive load involved in word learning as suggested by Goldin-Meadow and colleagues (2001). -> mémoriser une séquence de lettres, puis résolvent un pb de math, puis recall -> gestes pdt math pb > car save space for memorizing sequence of letter     
McGregor and colleagues (2009) suggest that gesture “externalized a meaningful aspect of the referent in the visual world. By making that meaning more obvious, gesture may free cognitive-linguistic resources for processing the word itself and, perhaps the other lexical and syntactic elements involved” (p. 823). Gestures could help reinforce the link between the lexical form and the concept it refers to by putting forward a distinctive property of the meaning the word refers to, depicting it and attracting the learner’s attention to it. Illustrating this link could free part of the cognitive load involved in finding this property and processing this link. This could free more cognitive load to actually learn the lexical form associated with it.         

Gestures could facilitate word learning by enhancing memorization and/or alleviating cognitive load.



#############################################################
Make gestures to learn: Reproducing gestures improves the learning of
anatomical knowledge more than just seeing gestures
########################################################

BIBLIO 


X Manual gestures can facilitate problem solving but also language or conceptual learning. Both seeing and making the gestures seems to be beneficial to cognitive tasks and learning. 
X anatomy = topic in embodied cognition because subject directly linked to body
X The movements we make do not only act on the outer world but they also shape our cognitive abilities. A broad range of neurological and behavioral evidences suggest that the motor system is involved in perception, decision making, lexical representation, memory and emotional processes (Barsalou, 2008; Casasanto & Dijkstra, 2010; Glenberg & Kaschak, 2002; Tyler et al., 2003; Wexler,Kosslyn, & Berthoz, 1998).
X Among the various body actions shown to influence our cognitive
X abilities, research paid particular attention to manual gestures, due to their multi-faceted representative function and their special relationship to language (Goldin-Meadow & Alibali, 2013;McNeill, 1992). Manual gestures are commonly and spontaneously used by speakers, learners and teachers. They were shown to support language learning on receptive and expressive sides as well as conceptual learning and problem solving (Kontra, Goldin-Meadow, & Beilock, 2012; Novack & Goldin-Meadow, 2015).
Making gestures to learn anatomy is also a specific case of embodied active
learning, in which explicit knowledge on the body is developed throughout the implication of the
body.
X These researches have been developed in conjunction with the theoretical
framework of “embodied cognition” (cf. Barsalou, 2008; Borghi & Pecher, 2011; Clark, 1999; Varela, Thompson, & Rosch, 1993; Wilson, 2002).
X According to the embodied cognition framework, mental functions are grounded in
X sensory-motor processes linked to specific situations (“grounded cognition”, see Barsalou, 2008). Therefore, cognitive representations are not amodal but rather “grounded” in the sensory-motor processes involved in their construction. In knowledge acquisition, as in all experiences, “the brain captures states across the modalities and integrates them with a multimodal representation stored in memory” (Barsalou, 2008, p.618).
X In this framework, cognitive processes rely on simulation
X mechanisms that could be defined as “the reenactment of perceptual, motor, and introspective states acquired during experience with the world, body, and mind” (Barsalou, 2008, p.619). As specific cases of sensory-motor experiences, and due to their powerful representational and deictic functions, manual gestures are the core interest of a variety of studies focused for instance on the role of gestures in language, conceptual learning, problem solving or spatial representations. The positive effect of gestures in these cognitive activities has been shown when seeing the gestures made by another person (a teacher, a discussion partner etc.) and when making the gestures.

X In a daily basis, people are spontaneously gesturing in order to communicate. These gestures can mark the rhythm of the discourse, strengthen the message or provide additional information to the listener.
X gestures could represent “a second channel that makes successful comprehension more likely” (Goldin-Meadow & Alibali, 2013, p.261).
X The effect of gestures on language comprehension however depends on the information contained in the gestures (Goldin-Meadow & Alibali, 2013)
X During class, teachers spontaneously gesture when they have to explain mathematical concepts to children (Goldin-Meadow, Kim, & Singer, 1999)

X Interestingly, Singer & Goldin-Meadow (2005) found that seeing gestures during a lesson of mathematics improves performance 24 hours after the lesson and tends to facilitate transfer to other problems solving.Teachers’ gestures can help children understand and integrate instruction, which can explain the positive effect on long-term performances. Here again, gestures should convey supplemental information to verbal information to be helpful: when children learn mathematics, they only improved when the teachers’ gestures bring a different way to approach the problem than the teacher’s spoken message.
X Early gestures do not only predict the lexical items, they also predict the vocabulary range (Iverson & Goldin-Meadow, 2005)
X For instance, in Church & Goldin-Meadow (1986), children had to explain their understanding of the concept of conservation while judging the same amount of water poured into two glasses with different shapes. When they explained their reasoning to solve the problem, some of them spontaneously produced gestures matching their reasoning while others produced gestures mismatching their reasoning. The latters were more likely to understand their mistakes, and better improve their performance than the formers.
X Chen (1996) have shown that gesturing while speaking could facilitate access to the mental lexicon in spontaneous speech produced by undergraduate students (Rauscher, Krauss, & Chen, 1996)
X adults can learn a second language easier if they gesture during learning (Gullberg, 2006; McCafferty, 2004)
X Hanoi : (Trofatter, Kontra, Beilock, & Goldin-Meadow, 2014) The students who made gestures during their explanation showed a greater improvement when they solved the Tower of Hanoi again than those who did not make gestures.
Students who gestured during learning had better performance than those who did not, both for the terminology (“knowledge of specific definitions and labels”) and comprehension (understanding of the structures and functions of the heart) tests (Macken & Ginns, 2014; p 598).

obj : rôle des gestes dans l'acquisition de nouvelles connaissances making>seeing
Indeed, a stronger activation of the motor system in the former case may create additional components to the memory traces and/or contribute to shape abilities to mentally simulate the function (Barsalou, 2008).

ARTICLE
The effect of making gestures was assessed by comparing two groups of participants (seeing vs. making gestures) both in terms of performance and subjective evaluation.
gestures “make learning last” (Cook et al., 2008).
Gesture behaviors were also monitored during the learning and test phases and the quantity of gestures made was related to the scores in the different evaluations.
Ability to memorize complex unknown words, assessed using a list of 8 pseudo-words with
two or three syllables that we generated from the Lexique 2 database (New, Pallier, Ferrand, & Matos, 2001). The pseudo-words were selected to have different orthographic organization.
The purpose of this study was to provide further evidences that making gestures can improve the acquisition of new knowledge. Anatomy learning was chosen as a specific case of embodied learning and as a challenging topic to learn. In particular, we focused on the specific contribution of making gestures in relation to the learning content as compared with just seeing gestures
Short-term subjective evaluations suggest that the Gesture group felt more engaged in the lecture than the Control group
Our study investigated the effect of a direct implication of the motor system when learning structural and functional anatomy. The results suggest that “doing gestures” is more effective than just “seeing gestures” while learning the names of anatomical structures. Such effect was previously observed at short-term in a mental rotation task (Goldin-Meadow et al., 2012) and is consistent with the idea that “motor information accrued by the body can affect learning and development by grounding mental representations in motor areas of the cortex and structuring associated perception” (Kontra, Goldin-
Meadow, & Beilock, 2012; p732).
the teacher’s gestures is already helpful for learning (Cook et al., 2013) being
active during learning is an important element in the research about learning and memory: Should learners gesture themselves or is seeing the teacher’s gestures enough?
Evidence suggesting that action itself rather than attention supports active learning is provided by Meijer & Van der Lubbe (2011): an active exploration of 3D objects leads to a better recognition of these objects than a passive exploration, even if participants had to carry out a secondary task during learning.
Previous work also suggests that being active during learning of anatomy improve the feeling of involvement, especially when innovative methods are used (cf. Sugan et al., 2010)
profils de gesturers, pas tous à l'aise pour faire des gestes.
Furthermore, the participants in the Gesture group were not only better than
those of the Control group: they also significantly improved their scores as compared with short-term assessment.
Similar beneficial effects of gestures on long-term learning was previously observed in
Cook et al., (2008) and Cook, Yip, & Goldin-Meadow (2010) and could be related to effects of sleep on memory. Literature broadly reported positive effect of sleep on memory consolidation (Diekelmann & Born, 2010; Rasch & Born, 2013).
Therefore, one or two nights of sleep could enhance memory traces by a (re)-simulation of experience (reactivation in the hippocampus) and a reorganization of the memory traces (by the dialogue between hippocampus and neocortex).
Sleep has a beneficial effect both on declarative and procedural memory (Plihal & Born, 1997; Rasch & Born, 2013).
The stronger motor activation when making gestures as compared to seeing gestures during learning may influence the reactivation of experience and the reorganization of memory during sleep, favoring the integration of the motor component.
The difference between the two groups also suggests that “seeing gestures” vs. “doing gestures” create different memory traces.
Sleep is for example well known to have a positive impact on procedural memory and visuo-spatial tasks (Fischer, Drosopoulos, Tsen, & Born, 2006; Peigneux et al., 2004; Björn Rasch, Büchel, Gais, & Born, 2007),
long-term effect of gestures on learning (Cook et al., 2008).
(1) the positive effect of making gestures could be present at short-term but hard to observe due to between-subjects design and to the multi-dimensional competences involved in complex learning such as anatomy; (2) longitudinal assessments should be planned systematically in learning studies, especially when comparing learning conditions, as some conditions may need sleep and/or time to be integrated

In terms of cognitive processes, we can assume that doing gestures during learning is a way to enhance the memory traces associated with learning. According to embodied cognition theories (Barsalou, 2008; Wilson, 2002), cognition emerges in the interaction between the body, the mind and the environment. Memory is defined by every sensory and motor component activated while experiencing the events from daily life (Logan, 1988; Versace et al., 2014). Several memory models are developed according to this idea and usually describe that the number of components of a memory trace can influence its strength (Versace et al., 2014). We can consider that having a supplemental motor component during learning (for the Gesture group) can strengthen the memory trace associated to this learning, if there is enough time (and/or sleeping processing) between learning and retrieval. The embodied cognition theories also suggest that memory is in fact a simulation of previous events (Barsalou, 2009; Barsalou, Pecher, Zeelenberg, Simmons, & Hamann, 2005). Adding a motor component to learning may facilitate the simulation process.
An opened question is then: Is the beneficial effect of gestures related to the type of link between the gestures and knowledge to learn?
Gestures seem to be useful in different domains (Susan Goldin-Meadow & Alibali, 2013; McCafferty, 2004; Novack & Goldin-Meadow, 2015; Trofatter et al., 2014) but the relevance of the link between learning content and gestures type remains an opened question.


###########################################################
When gesture does and does not promote learning
########################################################
Goldn-Meadow
gestes = tool for thinking and learning
convey info in gesture that is not conveyed in speech
reflect knowledge But also play role in changing knowledge
1/ reflect ready to learn : mismatch geste parole
2/ can promote learning
The children in the Cook and Goldin-Meadow (2006) study saw the teacher gesture and
either imitated those gestures or not. Children were not forced to gesture––they chose to. As a result, the children who gestured may have been systematically different from those who did not. In particular, the children who chose to gesture may have been more ready to learn than the children who chose not to gesture. If so, the fact that they reproduced the experimenter’s gestures may have been a reflection of that readiness to learn, rather than a causal factor in the learning itself.
knowledge can introduce new knowledge into a child's repertoire, but has to be a coherent gesture (speech+ correct gesture vs speech + partial incorrect gesture) mais toujours > à pas de geste

Broader et al 2007 BIBLIO
-> solving 6 mathematical equivalence problems without any instructions about what to do with their hands
-> puis 3 gp, no gesture, gestures, free
-> gestures added more new strategies : new trategies in gesture,not speech and was surprinsingly correct -> created mismatch or ready to learn ?


promote learning by activating implicing knowledge (already habe) or creating it ?
not only for children who had implicit knowledge -> gesture manipulations create knowledge (séparé en 2 groupes, impl ou pas)

how promotes learning ? effects only to gestures ?
- grounds thought in action -> add action information
( - Hanoi : une version avec poids inversés
-> gestes incompatibles (soulevement petit lourd à 1 main) -> réussit pas le test
pas d'effet dans no-switch condition
-> geste change représentaiton de la tâche )
- gesture lightens cognitive load, load of working memory
-> gesture while speaking requires coordination -> increase cognitive load ?
or integrated, work together ?
-> Goldin-Meadow et al. (2001) impact of gesturing on speaker's cognitive load :
gesturing on one task (explaining a math pb) affects perf on 2d task (remember list of words/letter) -> remember more items while gesturing
-> save speaker cognitive resources -> permit speaker to allocate more to mem task
matching gesture frees more cognitive load -> pas pur phénomène moteur
-> doit être en lien entre coordination de l'activité motrice avec des processus conceptuaux d'ordre >.

novice vs experts
-> mismatches produces by teachers, mais info disponible en speech et gesture
mismatch lighten moins cognitive load que match
-> chez expert, reflète instabilité, moment où speech/gesture pas aligné, reflétant the dynamc tension of speaking process (mc neill 1992)
McNeill, D. Hand and mind: What gestures reveal about thought. Chicago: The University of Chicago
Press; 1992.


##########################################################
Exercising during learning improves vocabulary acquisition:
Behavioral and ERP evidence
########################################
#bcp études montrent que activité physique améliore la plasticité corticale, et ralentit le déclin cortical des personnes âgées mais
effect of simultaneous physical activity on learning performances ?
positive correlation of exercise, learning and intelligence in children and young adults
-> physical activity pushes brain activity
-> effect different from motivation (physical activity during learnning) if increases in time
-> if physiological factors (augmente flux sanguin, hormones) -> stable sur 3 sem
-> subjects not particularly interested in physical ativity
-> test de vocabulaire français
-> chagements en plasticité cérébrale
-> la nouveauté ne peut pas expliquer ces résultats (9 sessions)
